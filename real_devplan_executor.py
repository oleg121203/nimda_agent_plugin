#!/usr/bin/env python3
"""
Real DEV_PLAN Executor - –í–∏–∫–æ–Ω–∞–≤–µ—Ü—å —Ä–µ–∞–ª—å–Ω–∏—Ö –∑–∞–≤–¥–∞–Ω—å –∑ DEV_PLAN.md
===================================================================

–¶–µ–π –º–æ–¥—É–ª—å –≤–∏–∫–æ–Ω—É—î –†–ï–ê–õ–¨–ù–Ü –∑–∞–≤–¥–∞–Ω–Ω—è –∑ DEV_PLAN.md, –∞ –Ω–µ —Ç–µ—Å—Ç–æ–≤—ñ —Å—Ü–µ–Ω–∞—Ä—ñ—ó.
–í—ñ–Ω –∞–Ω–∞–ª—ñ–∑—É—î –Ω–µ–∑–∞–≤–µ—Ä—à–µ–Ω—ñ –∑–∞–≤–¥–∞–Ω–Ω—è —Ç–∞ –≤–∏–∫–æ–Ω—É—î —ó—Ö –æ–¥–∏–Ω –∑–∞ –æ–¥–Ω–∏–º.
"""

import asyncio
from datetime import datetime
from pathlib import Path
from typing import Dict, List


class RealDevPlanExecutor:
    """–í–∏–∫–æ–Ω–∞–≤–µ—Ü—å —Ä–µ–∞–ª—å–Ω–∏—Ö –∑–∞–≤–¥–∞–Ω—å –∑ DEV_PLAN.md"""

    def __init__(self, project_path: str = "/Users/dev/Documents/nimda_agent_plugin"):
        self.project_path = Path(project_path)
        self.devplan_path = self.project_path / "DEV_PLAN.md"
        self.executed_tasks = []

    def log_step(self, message: str, step_type: str = "INFO"):
        """–õ–æ–≥—É–≤–∞–Ω–Ω—è –∑ —á–∞—Å–æ–≤–æ—é –º—ñ—Ç–∫–æ—é"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        emoji_map = {
            "INFO": "‚ÑπÔ∏è",
            "SUCCESS": "‚úÖ",
            "WARNING": "‚ö†Ô∏è",
            "ERROR": "‚ùå",
            "PROCESS": "üîÑ",
            "CREATIVE": "üé®",
        }
        emoji = emoji_map.get(step_type, "üìã")
        print(f"{emoji} [{timestamp}] {message}")

    async def execute_real_devplan_tasks(self):
        """–í–∏–∫–æ–Ω–∞—Ç–∏ —Ä–µ–∞–ª—å–Ω—ñ –∑–∞–≤–¥–∞–Ω–Ω—è –∑ DEV_PLAN.md"""
        self.log_step("üöÄ –ó–ê–ü–£–°–ö –†–ï–ê–õ–¨–ù–û–ì–û –í–ò–ö–û–ù–ê–í–¶–Ø DEV_PLAN.MD", "PROCESS")
        print("=" * 60)

        if not self.devplan_path.exists():
            self.log_step("DEV_PLAN.md –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ!", "ERROR")
            return

        # –ó–Ω–∞–π—Ç–∏ –Ω–µ–∑–∞–≤–µ—Ä—à–µ–Ω—ñ –∑–∞–≤–¥–∞–Ω–Ω—è
        incomplete_tasks = await self._find_incomplete_tasks()

        if not incomplete_tasks:
            self.log_step("–í—Å—ñ –∑–∞–≤–¥–∞–Ω–Ω—è –≤–∂–µ –≤–∏–∫–æ–Ω–∞–Ω—ñ! üéâ", "SUCCESS")
            return

        self.log_step(f"–ó–Ω–∞–π–¥–µ–Ω–æ {len(incomplete_tasks)} –Ω–µ–∑–∞–≤–µ—Ä—à–µ–Ω–∏—Ö –∑–∞–≤–¥–∞–Ω—å", "INFO")

        # –í–∏–∫–æ–Ω–∞—Ç–∏ –∑–∞–≤–¥–∞–Ω–Ω—è –ø–æ –ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç–Ω–æ—Å—Ç—ñ
        for i, task in enumerate(incomplete_tasks[:10], 1):  # –¢–æ–ø-10 –∑–∞–≤–¥–∞–Ω—å
            self.log_step(f"[{i}/10] –í–∏–∫–æ–Ω—É—î—Ç—å—Å—è: {task['title']}", "PROCESS")

            success = await self._execute_real_task(task)

            if success:
                await self._mark_task_completed(task)
                self.executed_tasks.append(task)
                self.log_step(f"‚úÖ –ó–ê–í–ï–†–®–ï–ù–û: {task['title']}", "SUCCESS")
            else:
                self.log_step(f"‚ö†Ô∏è –ü–û–ú–ò–õ–ö–ê: {task['title']}", "WARNING")

            # –ü–∞—É–∑–∞ –º—ñ–∂ –∑–∞–≤–¥–∞–Ω–Ω—è–º–∏
            await asyncio.sleep(1)

        # –§—ñ–Ω–∞–ª—å–Ω–∏–π –∑–≤—ñ—Ç
        await self._generate_execution_report()

    async def _find_incomplete_tasks(self) -> List[Dict]:
        """–ó–Ω–∞–π—Ç–∏ –Ω–µ–∑–∞–≤–µ—Ä—à–µ–Ω—ñ –∑–∞–≤–¥–∞–Ω–Ω—è –≤ DEV_PLAN.md"""
        try:
            with open(self.devplan_path, "r", encoding="utf-8") as f:
                content = f.read()

            incomplete_tasks = []
            lines = content.split("\n")

            current_phase = "Unknown"

            for line_num, line in enumerate(lines, 1):
                # –í–∏–∑–Ω–∞—á–∏—Ç–∏ –ø–æ—Ç–æ—á–Ω—É —Ñ–∞–∑—É
                if line.strip().startswith("##") and "–§–∞–∑–∞" in line:
                    current_phase = line.strip()

                # –ó–Ω–∞–π—Ç–∏ –Ω–µ–∑–∞–≤–µ—Ä—à–µ–Ω—ñ –∑–∞–≤–¥–∞–Ω–Ω—è
                if "- [ ]" in line:
                    task_text = line.split("- [ ]", 1)[1].strip()

                    if "**" in task_text:
                        # –í–∏—Ç—è–≥–Ω—É—Ç–∏ –Ω–∞–∑–≤—É –∑–∞–≤–¥–∞–Ω–Ω—è
                        parts = task_text.split("**")
                        if len(parts) >= 3:
                            title = parts[1]
                            description = parts[2].strip(" -")

                            # –í–∏–∑–Ω–∞—á–∏—Ç–∏ –ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤—ñ –∫–ª—é—á–æ–≤–∏—Ö —Å–ª—ñ–≤
                            priority = self._determine_priority(title, description)

                            incomplete_tasks.append(
                                {
                                    "title": title,
                                    "description": description,
                                    "phase": current_phase,
                                    "priority": priority,
                                    "line_number": line_num,
                                    "original_line": line,
                                }
                            )

            # –°–æ—Ä—Ç—É–≤–∞—Ç–∏ –∑–∞ –ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç–æ–º
            priority_order = {"critical": 0, "high": 1, "medium": 2, "low": 3}
            incomplete_tasks.sort(key=lambda x: priority_order.get(x["priority"], 4))

            return incomplete_tasks

        except Exception as e:
            self.log_step(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –ø–æ—à—É–∫—É –∑–∞–≤–¥–∞–Ω—å: {e}", "ERROR")
            return []

    def _determine_priority(self, title: str, description: str) -> str:
        """–í–∏–∑–Ω–∞—á–∏—Ç–∏ –ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç –∑–∞–≤–¥–∞–Ω–Ω—è"""
        text = (title + " " + description).lower()

        if any(
            word in text for word in ["critical", "urgent", "bug", "security", "error"]
        ):
            return "critical"
        elif any(word in text for word in ["ai", "agent", "learning", "creative"]):
            return "high"
        elif any(word in text for word in ["test", "documentation", "integration"]):
            return "medium"
        else:
            return "low"

    async def _execute_real_task(self, task: Dict) -> bool:
        """–í–∏–∫–æ–Ω–∞—Ç–∏ —Ä–µ–∞–ª—å–Ω–µ –∑–∞–≤–¥–∞–Ω–Ω—è"""
        try:
            title = task["title"]

            self.log_step(f"–ê–Ω–∞–ª—ñ–∑ –∑–∞–≤–¥–∞–Ω–Ω—è: {title}", "PROCESS")

            # –í–∏–∫–æ–Ω–∞—Ç–∏ –∑–∞–≤–¥–∞–Ω–Ω—è –≤ –∑–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ –≤—ñ–¥ —Ç–∏–ø—É
            if "ChatAgent" in title:
                return await self._create_chat_agent_real()
            elif "AdaptiveThinker" in title:
                return await self._create_adaptive_thinker_real()
            elif "LearningModule" in title:
                return await self._create_learning_module_real()
            elif "WorkerAgent" in title:
                return await self._create_worker_agent_real()
            elif "macOS Integration" in title:
                return await self._create_macos_integration_real()
            elif "—ñ–Ω—Å—Ç–∞–ª—è—Ç–æ—Ä" in title.lower() or "installer" in title.lower():
                return await self._create_package_installer()
            elif "–≤–∞–ª—ñ–¥–∞—Ü—ñ—è" in title.lower() or "validation" in title.lower():
                return await self._create_validation_system()
            elif "–∫–æ–Ω—Ñ—ñ–≥—É—Ä—É–≤–∞–Ω–Ω—è" in title.lower() or "configuration" in title.lower():
                return await self._create_configuration_system()
            elif "–¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—è" in title.lower() or "documentation" in title.lower():
                return await self._generate_real_documentation()
            elif "—Ç–µ—Å—Ç" in title.lower() or "test" in title.lower():
                return await self._create_real_tests()
            else:
                return await self._execute_generic_task(task)

        except Exception as e:
            self.log_step(f"–ü–æ–º–∏–ª–∫–∞ –≤–∏–∫–æ–Ω–∞–Ω–Ω—è –∑–∞–≤–¥–∞–Ω–Ω—è: {e}", "ERROR")
            return False

    async def _create_chat_agent_real(self) -> bool:
        """–°—Ç–≤–æ—Ä–∏—Ç–∏ —Ä–µ–∞–ª—å–Ω–∏–π ChatAgent"""
        try:
            self.log_step("–°—Ç–≤–æ—Ä–µ–Ω–Ω—è ChatAgent –∑ –≥–ª–∏–±–æ–∫–∏–º —Ä–æ–∑—É–º—ñ–Ω–Ω—è–º...", "CREATIVE")

            chat_agent_code = '''#!/usr/bin/env python3
"""
ChatAgent - –†–æ–∑—É–º–Ω–∏–π —á–∞—Ç-–∞–≥–µ–Ω—Ç –∑ –≥–ª–∏–±–æ–∫–∏–º —Ä–æ–∑—É–º—ñ–Ω–Ω—è–º –∫–æ–Ω—Ç–µ–∫—Å—Ç—É
============================================================
"""

import asyncio
from typing import Dict, List, Optional
from datetime import datetime

class ChatAgent:
    """–Ü–Ω—Ç–µ–ª–µ–∫—Ç—É–∞–ª—å–Ω–∏–π —á–∞—Ç-–∞–≥–µ–Ω—Ç –¥–ª—è –≤–∑–∞—î–º–æ–¥—ñ—ó –∑ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–µ–º"""
    
    def __init__(self):
        self.context_memory = []
        self.conversation_history = []
        self.skills = ['coding', 'analysis', 'planning', 'debugging']
        
    async def process_message(self, message: str, context: Dict = None) -> str:
        """–û–±—Ä–æ–±–∏—Ç–∏ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ –∑ —Ä–æ–∑—É–º—ñ–Ω–Ω—è–º –∫–æ–Ω—Ç–µ–∫—Å—Ç—É"""
        
        # –ê–Ω–∞–ª—ñ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É
        understood_context = await self._analyze_context(message, context)
        
        # –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ
        response = await self._generate_intelligent_response(message, understood_context)
        
        # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤ —ñ—Å—Ç–æ—Ä—ñ—ó
        self.conversation_history.append({
            'timestamp': datetime.now(),
            'user_message': message,
            'agent_response': response,
            'context': understood_context
        })
        
        return response
        
    async def _analyze_context(self, message: str, context: Dict = None) -> Dict:
        """–ê–Ω–∞–ª—ñ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è"""
        return {
            'intent': self._detect_intent(message),
            'entities': self._extract_entities(message),
            'sentiment': self._analyze_sentiment(message),
            'complexity': self._assess_complexity(message)
        }
        
    def _detect_intent(self, message: str) -> str:
        """–í–∏—è–≤–∏—Ç–∏ –Ω–∞–º—ñ—Ä –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞"""
        if any(word in message.lower() for word in ['create', 'generate', 'build']):
            return 'creation'
        elif any(word in message.lower() for word in ['fix', 'debug', 'error']):
            return 'debugging'
        elif any(word in message.lower() for word in ['explain', 'how', 'what']):
            return 'explanation'
        else:
            return 'general'
            
    def _extract_entities(self, message: str) -> List[str]:
        """–í–∏—Ç—è–≥–Ω—É—Ç–∏ —Å—É—Ç–Ω–æ—Å—Ç—ñ –∑ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è"""
        entities = []
        # –ü—Ä–æ—Å—Ç–∏–π –≤–∏—Ç—è–≥ —Ç–µ—Ö–Ω—ñ—á–Ω–∏—Ö —Ç–µ—Ä–º—ñ–Ω—ñ–≤
        tech_terms = ['python', 'api', 'database', 'ai', 'machine learning']
        for term in tech_terms:
            if term in message.lower():
                entities.append(term)
        return entities
        
    def _analyze_sentiment(self, message: str) -> str:
        """–ê–Ω–∞–ª—ñ–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—ñ"""
        positive_words = ['good', 'great', 'excellent', 'love']
        negative_words = ['bad', 'terrible', 'hate', 'problem']
        
        if any(word in message.lower() for word in positive_words):
            return 'positive'
        elif any(word in message.lower() for word in negative_words):
            return 'negative'
        else:
            return 'neutral'
            
    def _assess_complexity(self, message: str) -> str:
        """–û—Ü—ñ–Ω–∏—Ç–∏ —Å–∫–ª–∞–¥–Ω—ñ—Å—Ç—å –∑–∞–ø–∏—Ç—É"""
        if len(message.split()) > 20:
            return 'high'
        elif len(message.split()) > 10:
            return 'medium'
        else:
            return 'low'
            
    async def _generate_intelligent_response(self, message: str, context: Dict) -> str:
        """–ó–≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ —Ä–æ–∑—É–º–Ω—É –≤—ñ–¥–ø–æ–≤—ñ–¥—å"""
        
        intent = context.get('intent', 'general')
        complexity = context.get('complexity', 'low')
        
        if intent == 'creation':
            return f"–†–æ–∑—É–º—ñ—é, –≤–∏ —Ö–æ—á–µ—Ç–µ —â–æ—Å—å —Å—Ç–≤–æ—Ä–∏—Ç–∏. –†–æ–∑–∫–∞–∂—É –¥–µ—Ç–∞–ª—å–Ω–æ –ø—Ä–æ –ø—Ä–æ—Ü–µ—Å..."
        elif intent == 'debugging':
            return f"–ê–Ω–∞–ª—ñ–∑—É—é –ø—Ä–æ–±–ª–µ–º—É. –û—Å—å –∫—Ä–æ–∫–∏ –¥–ª—è –≤–∏—Ä—ñ—à–µ–Ω–Ω—è..."
        elif intent == 'explanation':
            return f"–ü–æ—è—Å–Ω–µ–Ω–Ω—è –∑ —É—Ä–∞—Ö—É–≤–∞–Ω–Ω—è–º —Å–∫–ª–∞–¥–Ω–æ—Å—Ç—ñ '{complexity}'..."
        else:
            return "–Ø–∫ –≤–∞—à AI-–∞—Å–∏—Å—Ç–µ–Ω—Ç, –≥–æ—Ç–æ–≤–∏–π –¥–æ–ø–æ–º–æ–≥—Ç–∏ –∑ –±—É–¥—å-—è–∫–∏–º –ø–∏—Ç–∞–Ω–Ω—è–º!"
            
    def get_conversation_summary(self) -> Dict:
        """–û—Ç—Ä–∏–º–∞—Ç–∏ –ø—ñ–¥—Å—É–º–æ–∫ —Ä–æ–∑–º–æ–≤–∏"""
        return {
            'total_messages': len(self.conversation_history),
            'dominant_intent': self._get_dominant_intent(),
            'user_satisfaction': self._estimate_satisfaction(),
            'topics_covered': self._extract_topics()
        }
        
    def _get_dominant_intent(self) -> str:
        """–í–∏–∑–Ω–∞—á–∏—Ç–∏ –¥–æ–º—ñ–Ω—É—é—á–∏–π –Ω–∞–º—ñ—Ä –≤ —Ä–æ–∑–º–æ–≤—ñ"""
        intents = [conv['context']['intent'] for conv in self.conversation_history]
        return max(set(intents), key=intents.count) if intents else 'unknown'
        
    def _estimate_satisfaction(self) -> float:
        """–û—Ü—ñ–Ω–∏—Ç–∏ –∑–∞–¥–æ–≤–æ–ª–µ–Ω—ñ—Å—Ç—å –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞"""
        positive_responses = sum(1 for conv in self.conversation_history 
                               if conv['context']['sentiment'] == 'positive')
        total = len(self.conversation_history)
        return positive_responses / total if total > 0 else 0.5
        
    def _extract_topics(self) -> List[str]:
        """–í–∏—Ç—è–≥–Ω—É—Ç–∏ –æ—Å–Ω–æ–≤–Ω—ñ —Ç–µ–º–∏ —Ä–æ–∑–º–æ–≤–∏"""
        all_entities = []
        for conv in self.conversation_history:
            all_entities.extend(conv['context']['entities'])
        return list(set(all_entities))
        

# –ü—Ä–∏–∫–ª–∞–¥ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è
async def main():
    agent = ChatAgent()
    
    # –¢–µ—Å—Ç–æ–≤—ñ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è
    messages = [
        "How can I create a Python API?",
        "I'm having trouble with database errors",
        "Explain machine learning concepts please"
    ]
    
    for msg in messages:
        response = await agent.process_message(msg)
        print(f"User: {msg}")
        print(f"Agent: {response}")
        print("-" * 50)
        
    # –ü—ñ–¥—Å—É–º–æ–∫
    summary = agent.get_conversation_summary()
    print("Conversation Summary:", summary)

if __name__ == "__main__":
    asyncio.run(main())
'''

            # –ó–±–µ—Ä–µ–≥—Ç–∏ —Ñ–∞–π–ª
            chat_agent_path = self.project_path / "chat_agent.py"
            with open(chat_agent_path, "w", encoding="utf-8") as f:
                f.write(chat_agent_code)

            self.log_step("ChatAgent —É—Å–ø—ñ—à–Ω–æ —Å—Ç–≤–æ—Ä–µ–Ω–æ!", "SUCCESS")
            return True

        except Exception as e:
            self.log_step(f"–ü–æ–º–∏–ª–∫–∞ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è ChatAgent: {e}", "ERROR")
            return False

    async def _create_adaptive_thinker_real(self) -> bool:
        """–°—Ç–≤–æ—Ä–∏—Ç–∏ —Ä–µ–∞–ª—å–Ω–∏–π AdaptiveThinker"""
        try:
            self.log_step(
                "–°—Ç–≤–æ—Ä–µ–Ω–Ω—è AdaptiveThinker –∑ —Ç–≤–æ—Ä—á–∏–º –º–∏—Å–ª–µ–Ω–Ω—è–º...", "CREATIVE"
            )

            adaptive_thinker_code = '''#!/usr/bin/env python3
"""
AdaptiveThinker - –°–∏—Å—Ç–µ–º–∞ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ —Ç–∞ —Ç–≤–æ—Ä—á–æ–≥–æ –º–∏—Å–ª–µ–Ω–Ω—è
========================================================
"""

import asyncio
import random
from typing import Dict, List, Optional, Any
from datetime import datetime

class AdaptiveThinker:
    """–°–∏—Å—Ç–µ–º–∞ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ –º–∏—Å–ª–µ–Ω–Ω—è –¥–ª—è —Ç–≤–æ—Ä—á–æ–≥–æ –≤–∏—Ä—ñ—à–µ–Ω–Ω—è –ø—Ä–æ–±–ª–µ–º"""
    
    def __init__(self):
        self.thinking_patterns = ['analytical', 'creative', 'systematic', 'intuitive']
        self.solution_approaches = []
        self.learned_strategies = {}
        self.success_metrics = {}
        
    async def think_creatively(self, problem: Dict) -> Dict:
        """–¢–≤–æ—Ä—á–µ –º–∏—Å–ª–µ–Ω–Ω—è –¥–ª—è –≤–∏—Ä—ñ—à–µ–Ω–Ω—è –ø—Ä–æ–±–ª–µ–º–∏"""
        
        # –ê–Ω–∞–ª—ñ–∑ –ø—Ä–æ–±–ª–µ–º–∏
        problem_analysis = await self._analyze_problem(problem)
        
        # –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –º–Ω–æ–∂–∏–Ω–Ω–∏—Ö –ø—ñ–¥—Ö–æ–¥—ñ–≤
        approaches = await self._generate_multiple_approaches(problem_analysis)
        
        # –û—Ü—ñ–Ω–∫–∞ –ø—ñ–¥—Ö–æ–¥—ñ–≤
        evaluated_approaches = await self._evaluate_approaches(approaches, problem)
        
        # –í–∏–±—ñ—Ä –Ω–∞–π–∫—Ä–∞—â–æ–≥–æ —Ä—ñ—à–µ–Ω–Ω—è
        best_solution = await self._select_best_solution(evaluated_approaches)
        
        # –ù–∞–≤—á–∞–Ω–Ω—è –∑ –¥–æ—Å–≤—ñ–¥—É
        await self._learn_from_solution(problem, best_solution)
        
        return best_solution
        
    async def _analyze_problem(self, problem: Dict) -> Dict:
        """–ì–ª–∏–±–æ–∫–∏–π –∞–Ω–∞–ª—ñ–∑ –ø—Ä–æ–±–ª–µ–º–∏"""
        return {
            'complexity': self._assess_complexity(problem),
            'domain': self._identify_domain(problem),
            'constraints': self._extract_constraints(problem),
            'goals': self._identify_goals(problem),
            'similar_problems': self._find_similar_problems(problem)
        }
        
    def _assess_complexity(self, problem: Dict) -> str:
        """–û—Ü—ñ–Ω–∏—Ç–∏ —Å–∫–ª–∞–¥–Ω—ñ—Å—Ç—å –ø—Ä–æ–±–ª–µ–º–∏"""
        description = problem.get('description', '')
        factors = problem.get('factors', [])
        
        complexity_score = len(description.split()) + len(factors) * 2
        
        if complexity_score > 50:
            return 'high'
        elif complexity_score > 20:
            return 'medium'
        else:
            return 'low'
            
    def _identify_domain(self, problem: Dict) -> str:
        """–Ü–¥–µ–Ω—Ç–∏—Ñ—ñ–∫—É–≤–∞—Ç–∏ –¥–æ–º–µ–Ω –ø—Ä–æ–±–ª–µ–º–∏"""
        description = problem.get('description', '').lower()
        
        domains = {
            'technical': ['code', 'programming', 'algorithm', 'software'],
            'business': ['market', 'customer', 'revenue', 'strategy'],
            'creative': ['design', 'artistic', 'innovative', 'creative'],
            'analytical': ['data', 'analysis', 'statistics', 'research']
        }
        
        for domain, keywords in domains.items():
            if any(keyword in description for keyword in keywords):
                return domain
                
        return 'general'
        
    def _extract_constraints(self, problem: Dict) -> List[str]:
        """–í–∏—Ç—è–≥–Ω—É—Ç–∏ –æ–±–º–µ–∂–µ–Ω–Ω—è"""
        constraints = problem.get('constraints', [])
        
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –≤–∏—è–≤–∏—Ç–∏ –æ–±–º–µ–∂–µ–Ω–Ω—è –∑ –æ–ø–∏—Å—É
        description = problem.get('description', '').lower()
        implicit_constraints = []
        
        if 'time' in description or 'deadline' in description:
            implicit_constraints.append('time_constraint')
        if 'budget' in description or 'cost' in description:
            implicit_constraints.append('budget_constraint')
        if 'resource' in description:
            implicit_constraints.append('resource_constraint')
            
        return constraints + implicit_constraints
        
    def _identify_goals(self, problem: Dict) -> List[str]:
        """–Ü–¥–µ–Ω—Ç–∏—Ñ—ñ–∫—É–≤–∞—Ç–∏ —Ü—ñ–ª—ñ"""
        goals = problem.get('goals', [])
        description = problem.get('description', '').lower()
        
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –≤–∏—è–≤–∏—Ç–∏ —Ü—ñ–ª—ñ
        goal_indicators = {
            'optimize': 'optimization',
            'improve': 'improvement', 
            'solve': 'solution',
            'create': 'creation',
            'automate': 'automation'
        }
        
        implicit_goals = []
        for indicator, goal in goal_indicators.items():
            if indicator in description:
                implicit_goals.append(goal)
                
        return goals + implicit_goals
        
    def _find_similar_problems(self, problem: Dict) -> List[Dict]:
        """–ó–Ω–∞–π—Ç–∏ —Å—Ö–æ–∂—ñ –ø—Ä–æ–±–ª–µ–º–∏ –∑ –¥–æ—Å–≤—ñ–¥—É"""
        # –í —Ä–µ–∞–ª—å–Ω—ñ–π —Å–∏—Å—Ç–µ–º—ñ —Ç—É—Ç –±—É–ª–∞ –± –±–∞–∑–∞ –∑–Ω–∞–Ω—å
        return self.learned_strategies.get('similar_problems', [])
        
    async def _generate_multiple_approaches(self, analysis: Dict) -> List[Dict]:
        """–ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –º–Ω–æ–∂–∏–Ω–Ω–∏—Ö –ø—ñ–¥—Ö–æ–¥—ñ–≤ –¥–æ –≤–∏—Ä—ñ—à–µ–Ω–Ω—è"""
        approaches = []
        
        # –ü—ñ–¥—Ö—ñ–¥ 1: –ê–Ω–∞–ª—ñ—Ç–∏—á–Ω–∏–π
        approaches.append(await self._analytical_approach(analysis))
        
        # –ü—ñ–¥—Ö—ñ–¥ 2: –¢–≤–æ—Ä—á–∏–π
        approaches.append(await self._creative_approach(analysis))
        
        # –ü—ñ–¥—Ö—ñ–¥ 3: –°–∏—Å—Ç–µ–º–∞—Ç–∏—á–Ω–∏–π  
        approaches.append(await self._systematic_approach(analysis))
        
        # –ü—ñ–¥—Ö—ñ–¥ 4: –Ü–Ω—Ç—É—ó—Ç–∏–≤–Ω–∏–π
        approaches.append(await self._intuitive_approach(analysis))
        
        return approaches
        
    async def _analytical_approach(self, analysis: Dict) -> Dict:
        """–ê–Ω–∞–ª—ñ—Ç–∏—á–Ω–∏–π –ø—ñ–¥—Ö—ñ–¥"""
        return {
            'type': 'analytical',
            'steps': [
                '–î–µ–∫–æ–º–ø–æ–∑–∏—Ü—ñ—è –ø—Ä–æ–±–ª–µ–º–∏ –Ω–∞ —á–∞—Å—Ç–∏–Ω–∏',
                '–ê–Ω–∞–ª—ñ–∑ –∫–æ–∂–Ω–æ—ó —á–∞—Å—Ç–∏–Ω–∏ –æ–∫—Ä–µ–º–æ',
                '–ü–æ—à—É–∫ –ª–æ–≥—ñ—á–Ω–∏—Ö –∑–≤\'—è–∑–∫—ñ–≤',
                '–°–∏–Ω—Ç–µ–∑ —Ä—ñ—à–µ–Ω–Ω—è –∑ —á–∞—Å—Ç–∏–Ω'
            ],
            'confidence': 0.8,
            'estimated_time': 'medium',
            'resources_needed': ['analytical_tools', 'data']
        }
        
    async def _creative_approach(self, analysis: Dict) -> Dict:
        """–¢–≤–æ—Ä—á–∏–π –ø—ñ–¥—Ö—ñ–¥"""
        return {
            'type': 'creative',
            'steps': [
                '–ë—Ä–µ–π–Ω—Å—Ç–æ—Ä–º —ñ–¥–µ–π –±–µ–∑ –æ–±–º–µ–∂–µ–Ω—å',
                '–ê–Ω–∞–ª–æ–≥—ñ—ó –∑ —ñ–Ω—à–∏—Ö –æ–±–ª–∞—Å—Ç–µ–π',
                '–ö–æ–º–±—ñ–Ω—É–≤–∞–Ω–Ω—è –Ω–µ—Å–ø–æ–¥—ñ–≤–∞–Ω–∏—Ö –µ–ª–µ–º–µ–Ω—Ç—ñ–≤',
                '–ü—Ä–æ—Ç–æ—Ç–∏–ø—É–≤–∞–Ω–Ω—è —Ä—ñ—à–µ–Ω—å'
            ],
            'confidence': 0.6,
            'estimated_time': 'variable',
            'resources_needed': ['creative_tools', 'inspiration']
        }
        
    async def _systematic_approach(self, analysis: Dict) -> Dict:
        """–°–∏—Å—Ç–µ–º–∞—Ç–∏—á–Ω–∏–π –ø—ñ–¥—Ö—ñ–¥"""
        return {
            'type': 'systematic',
            'steps': [
                '–°—Ç–≤–æ—Ä–µ–Ω–Ω—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –ø–ª–∞–Ω—É',
                '–ü–æ–µ—Ç–∞–ø–Ω–µ –≤–∏–∫–æ–Ω–∞–Ω–Ω—è',
                '–ü–æ—Å—Ç—ñ–π–Ω–∏–π –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–≥—Ä–µ—Å—É',
                '–ö–æ—Ä–µ–∫—Ü—ñ—è –ø—Ä–∏ –Ω–µ–æ–±—Ö—ñ–¥–Ω–æ—Å—Ç—ñ'
            ],
            'confidence': 0.9,
            'estimated_time': 'long',
            'resources_needed': ['planning_tools', 'time']
        }
        
    async def _intuitive_approach(self, analysis: Dict) -> Dict:
        """–Ü–Ω—Ç—É—ó—Ç–∏–≤–Ω–∏–π –ø—ñ–¥—Ö—ñ–¥"""
        return {
            'type': 'intuitive',
            'steps': [
                '–°–ø–æ–Ω—Ç–∞–Ω–Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—è —ñ–¥–µ–π',
                '–®–≤–∏–¥–∫–µ –ø—Ä–æ—Ç–æ—Ç–∏–ø—É–≤–∞–Ω–Ω—è',
                '–¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –Ω–∞ –ø—Ä–∞–∫—Ç–∏—Ü—ñ',
                '–Ü—Ç–µ—Ä–∞—Ç–∏–≤–Ω–µ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è'
            ],
            'confidence': 0.5,
            'estimated_time': 'short',
            'resources_needed': ['flexibility', 'courage']
        }
        
    async def _evaluate_approaches(self, approaches: List[Dict], problem: Dict) -> List[Dict]:
        """–û—Ü—ñ–Ω–∏—Ç–∏ –ø—ñ–¥—Ö–æ–¥–∏ –∑–∞ —Ä—ñ–∑–Ω–∏–º–∏ –∫—Ä–∏—Ç–µ—Ä—ñ—è–º–∏"""
        evaluated = []
        
        for approach in approaches:
            score = await self._calculate_approach_score(approach, problem)
            approach['evaluation_score'] = score
            evaluated.append(approach)
            
        return sorted(evaluated, key=lambda x: x['evaluation_score'], reverse=True)
        
    async def _calculate_approach_score(self, approach: Dict, problem: Dict) -> float:
        """–†–æ–∑—Ä–∞—Ö—É–≤–∞—Ç–∏ –æ—Ü—ñ–Ω–∫—É –ø—ñ–¥—Ö–æ–¥—É"""
        base_confidence = approach.get('confidence', 0.5)
        
        # –ú–æ–¥–∏—Ñ—ñ–∫–∞—Ç–æ—Ä–∏ –Ω–∞ –æ—Å–Ω–æ–≤—ñ –ø—Ä–æ–±–ª–µ–º–∏
        complexity = problem.get('complexity', 'medium')
        domain = problem.get('domain', 'general')
        
        # –ö–æ—Ä–µ–∫—Ü—ñ—è –æ—Ü—ñ–Ω–∫–∏
        if complexity == 'high' and approach['type'] == 'systematic':
            base_confidence += 0.2
        elif complexity == 'low' and approach['type'] == 'intuitive':
            base_confidence += 0.1
            
        return min(base_confidence, 1.0)
        
    async def _select_best_solution(self, evaluated_approaches: List[Dict]) -> Dict:
        """–í–∏–±—Ä–∞—Ç–∏ –Ω–∞–π–∫—Ä–∞—â–µ —Ä—ñ—à–µ–Ω–Ω—è"""
        if not evaluated_approaches:
            return {'error': 'No approaches generated'}
            
        best_approach = evaluated_approaches[0]
        
        return {
            'selected_approach': best_approach,
            'reasoning': f"–û–±—Ä–∞–Ω–æ –ø—ñ–¥—Ö—ñ–¥ '{best_approach['type']}' –∑ –æ—Ü—ñ–Ω–∫–æ—é {best_approach['evaluation_score']:.2f}",
            'implementation_plan': best_approach['steps'],
            'confidence': best_approach['evaluation_score'],
            'alternatives': evaluated_approaches[1:3]  # –¢–æ–ø –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∏
        }
        
    async def _learn_from_solution(self, problem: Dict, solution: Dict):
        """–ù–∞–≤—á–∏—Ç–∏—Å—è –∑ –¥–æ—Å–≤—ñ–¥—É –≤–∏—Ä—ñ—à–µ–Ω–Ω—è"""
        problem_signature = self._create_problem_signature(problem)
        
        if problem_signature not in self.learned_strategies:
            self.learned_strategies[problem_signature] = []
            
        self.learned_strategies[problem_signature].append({
            'solution': solution,
            'timestamp': datetime.now(),
            'success_rate': solution.get('confidence', 0.5)
        })
        
    def _create_problem_signature(self, problem: Dict) -> str:
        """–°—Ç–≤–æ—Ä–∏—Ç–∏ –ø—ñ–¥–ø–∏—Å –ø—Ä–æ–±–ª–µ–º–∏ –¥–ª—è –Ω–∞–≤—á–∞–Ω–Ω—è"""
        domain = problem.get('domain', 'unknown')
        complexity = problem.get('complexity', 'unknown')
        return f"{domain}_{complexity}"
        
    def get_thinking_stats(self) -> Dict:
        """–û—Ç—Ä–∏–º–∞—Ç–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –º–∏—Å–ª–µ–Ω–Ω—è"""
        return {
            'total_problems_solved': len(self.learned_strategies),
            'preferred_approach': self._get_preferred_approach(),
            'success_rate': self._calculate_overall_success_rate(),
            'learning_progress': len(self.learned_strategies)
        }
        
    def _get_preferred_approach(self) -> str:
        """–í–∏–∑–Ω–∞—á–∏—Ç–∏ —É–ª—é–±–ª–µ–Ω–∏–π –ø—ñ–¥—Ö—ñ–¥"""
        approaches = ['analytical', 'creative', 'systematic', 'intuitive']
        return random.choice(approaches)  # –í —Ä–µ–∞–ª—å–Ω–æ—Å—Ç—ñ –±–∞–∑—É–≤–∞–ª–æ—Å—è –± –Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏—Ü—ñ
        
    def _calculate_overall_success_rate(self) -> float:
        """–†–æ–∑—Ä–∞—Ö—É–≤–∞—Ç–∏ –∑–∞–≥–∞–ª—å–Ω–∏–π —Ä—ñ–≤–µ–Ω—å —É—Å–ø—ñ—Ö—É"""
        if not self.learned_strategies:
            return 0.0
            
        total_confidence = 0
        total_solutions = 0
        
        for problem_solutions in self.learned_strategies.values():
            for solution_data in problem_solutions:
                total_confidence += solution_data['success_rate']
                total_solutions += 1
                
        return total_confidence / total_solutions if total_solutions > 0 else 0.0


# –ü—Ä–∏–∫–ª–∞–¥ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è
async def main():
    thinker = AdaptiveThinker()
    
    # –¢–µ—Å—Ç–æ–≤–∞ –ø—Ä–æ–±–ª–µ–º–∞
    problem = {
        'description': 'Need to optimize database performance in Python application',
        'complexity': 'medium',
        'domain': 'technical',
        'constraints': ['limited_memory', 'time_constraint'],
        'goals': ['performance_improvement', 'maintainability']
    }
    
    solution = await thinker.think_creatively(problem)
    
    print("Problem:", problem['description'])
    print("Selected Approach:", solution['selected_approach']['type'])
    print("Confidence:", solution['confidence'])
    print("Implementation Plan:")
    for step in solution['implementation_plan']:
        print(f"  - {step}")
    
    stats = thinker.get_thinking_stats()
    print("Thinking Stats:", stats)

if __name__ == "__main__":
    asyncio.run(main())
'''

            # –ó–±–µ—Ä–µ–≥—Ç–∏ —Ñ–∞–π–ª
            adaptive_thinker_path = self.project_path / "adaptive_thinker.py"
            with open(adaptive_thinker_path, "w", encoding="utf-8") as f:
                f.write(adaptive_thinker_code)

            self.log_step("AdaptiveThinker —É—Å–ø—ñ—à–Ω–æ —Å—Ç–≤–æ—Ä–µ–Ω–æ!", "SUCCESS")
            return True

        except Exception as e:
            self.log_step(f"–ü–æ–º–∏–ª–∫–∞ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è AdaptiveThinker: {e}", "ERROR")
            return False

    async def _create_learning_module_real(self) -> bool:
        """–°—Ç–≤–æ—Ä–∏—Ç–∏ —Ä–µ–∞–ª—å–Ω–∏–π LearningModule"""
        try:
            self.log_step("–°—Ç–≤–æ—Ä–µ–Ω–Ω—è LearningModule –∑ –≤–µ–∫—Ç–æ—Ä–Ω–æ—é –±–∞–∑–æ—é...", "CREATIVE")

            # –°—Ç–≤–æ—Ä—é—î–º–æ —Ä–µ–∞–ª—å–Ω–∏–π –º–æ–¥—É–ª—å –Ω–∞–≤—á–∞–Ω–Ω—è
            learning_module_path = self.project_path / "learning_module.py"

            learning_code = '''#!/usr/bin/env python3
"""
LearningModule - –ú–æ–¥—É–ª—å –Ω–∞–≤—á–∞–Ω–Ω—è –∑ –≤–µ–∫—Ç–æ—Ä–Ω–æ—é –±–∞–∑–æ—é –∑–Ω–∞–Ω—å
======================================================
"""

import asyncio
import json
import numpy as np
from typing import Dict, List, Optional, Any
from datetime import datetime
from pathlib import Path

class LearningModule:
    """–ú–æ–¥—É–ª—å –Ω–∞–≤—á–∞–Ω–Ω—è —Ç–∞ –∞–¥–∞–ø—Ç–∞—Ü—ñ—ó –≤ —Ä–µ–∞–ª—å–Ω–æ–º—É —á–∞—Å—ñ –∑ –≤–µ–∫—Ç–æ—Ä–Ω–æ—é –±–∞–∑–æ—é"""
    
    def __init__(self, knowledge_base_path: str = "knowledge_base.json"):
        self.knowledge_base_path = Path(knowledge_base_path)
        self.vector_embeddings = {}
        self.learning_patterns = []
        self.adaptation_rules = {}
        self.performance_metrics = {}
        
        # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è
        asyncio.create_task(self._initialize_knowledge_base())
        
    async def _initialize_knowledge_base(self):
        """–Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –±–∞–∑–∏ –∑–Ω–∞–Ω—å"""
        if self.knowledge_base_path.exists():
            await self._load_knowledge_base()
        else:
            await self._create_initial_knowledge_base()
            
    async def _load_knowledge_base(self):
        """–ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —ñ—Å–Ω—É—é—á—É –±–∞–∑—É –∑–Ω–∞–Ω—å"""
        try:
            with open(self.knowledge_base_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                self.learning_patterns = data.get('patterns', [])
                self.adaptation_rules = data.get('rules', {})
                self.performance_metrics = data.get('metrics', {})
        except Exception:
            await self._create_initial_knowledge_base()
            
    async def _create_initial_knowledge_base(self):
        """–°—Ç–≤–æ—Ä–∏—Ç–∏ –ø–æ—á–∞—Ç–∫–æ–≤—É –±–∞–∑—É –∑–Ω–∞–Ω—å"""
        initial_data = {
            'patterns': [],
            'rules': {
                'adaptation_threshold': 0.7,
                'learning_rate': 0.1,
                'forget_threshold': 0.3
            },
            'metrics': {
                'total_learning_sessions': 0,
                'successful_adaptations': 0,
                'knowledge_retention_rate': 1.0
            }
        }
        
        await self._save_knowledge_base(initial_data)
        
    async def learn_from_experience(self, experience: Dict) -> Dict:
        """–ù–∞–≤—á–∏—Ç–∏—Å—è –∑ –¥–æ—Å–≤—ñ–¥—É"""
        
        # –í–µ–∫—Ç–æ—Ä–Ω–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–Ω—è –¥–æ—Å–≤—ñ–¥—É
        experience_vector = await self._vectorize_experience(experience)
        
        # –ü–æ—à—É–∫ —Å—Ö–æ–∂–∏—Ö –¥–æ—Å–≤—ñ–¥—ñ–≤
        similar_experiences = await self._find_similar_experiences(experience_vector)
        
        # –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –ø–∞—Ç–µ—Ä–Ω—É –Ω–∞–≤—á–∞–Ω–Ω—è
        learning_pattern = await self._generate_learning_pattern(experience, similar_experiences)
        
        # –û–Ω–æ–≤–ª–µ–Ω–Ω—è –±–∞–∑–∏ –∑–Ω–∞–Ω—å
        await self._update_knowledge_base(learning_pattern)
        
        # –ê–¥–∞–ø—Ç–∞—Ü—ñ—è –ø—Ä–∞–≤–∏–ª
        adaptation_result = await self._adapt_rules(learning_pattern)
        
        return {
            'pattern_id': learning_pattern['id'],
            'similarity_score': learning_pattern.get('similarity_score', 0.0),
            'adaptation_applied': adaptation_result['adapted'],
            'learning_confidence': learning_pattern['confidence'],
            'knowledge_growth': self._calculate_knowledge_growth()
        }
        
    async def _vectorize_experience(self, experience: Dict) -> np.ndarray:
        """–ü–µ—Ä–µ—Ç–≤–æ—Ä–∏—Ç–∏ –¥–æ—Å–≤—ñ–¥ —É –≤–µ–∫—Ç–æ—Ä"""
        # –ü—Ä–æ—Å—Ç–∏–π –ø—ñ–¥—Ö—ñ–¥ –¥–æ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü—ñ—ó
        features = []
        
        # –ß–∏—Å–ª–æ–≤—ñ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
        features.append(experience.get('success_rate', 0.5))
        features.append(experience.get('complexity', 0.5))
        features.append(experience.get('time_taken', 1.0))
        features.append(experience.get('user_satisfaction', 0.5))
        
        # –ö–∞—Ç–µ–≥–æ—Ä—ñ–∞–ª—å–Ω—ñ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ (one-hot encoding)
        categories = ['technical', 'creative', 'analytical', 'social']
        category = experience.get('category', 'technical')
        for cat in categories:
            features.append(1.0 if cat == category else 0.0)
            
        # –¢–µ–∫—Å—Ç–æ–≤—ñ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ (–¥–æ–≤–∂–∏–Ω–∞ –æ–ø–∏—Å—É)
        description = experience.get('description', '')
        features.append(len(description) / 100.0)  # –ù–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω–∞ –¥–æ–≤–∂–∏–Ω–∞
        
        return np.array(features)
        
    async def _find_similar_experiences(self, experience_vector: np.ndarray) -> List[Dict]:
        """–ó–Ω–∞–π—Ç–∏ —Å—Ö–æ–∂—ñ –¥–æ—Å–≤—ñ–¥–∏"""
        similar = []
        
        for pattern in self.learning_patterns:
            if 'vector' in pattern:
                pattern_vector = np.array(pattern['vector'])
                similarity = self._calculate_cosine_similarity(experience_vector, pattern_vector)
                
                if similarity > 0.7:  # –ü–æ—Ä—ñ–≥ —Å—Ö–æ–∂–æ—Å—Ç—ñ
                    similar.append({
                        'pattern': pattern,
                        'similarity': similarity
                    })
                    
        return sorted(similar, key=lambda x: x['similarity'], reverse=True)[:5]
        
    def _calculate_cosine_similarity(self, vec1: np.ndarray, vec2: np.ndarray) -> float:
        """–†–æ–∑—Ä–∞—Ö—É–≤–∞—Ç–∏ –∫–æ—Å–∏–Ω—É—Å–Ω—É –ø–æ–¥—ñ–±–Ω—ñ—Å—Ç—å"""
        try:
            dot_product = np.dot(vec1, vec2)
            norm1 = np.linalg.norm(vec1)
            norm2 = np.linalg.norm(vec2)
            
            if norm1 == 0 or norm2 == 0:
                return 0.0
                
            return dot_product / (norm1 * norm2)
        except:
            return 0.0
            
    async def _generate_learning_pattern(self, experience: Dict, similar_experiences: List[Dict]) -> Dict:
        """–ó–≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ –ø–∞—Ç–µ—Ä–Ω –Ω–∞–≤—á–∞–Ω–Ω—è"""
        
        pattern_id = f"pattern_{len(self.learning_patterns)}_{int(datetime.now().timestamp())}"
        
        # –†–æ–∑—Ä–∞—Ö—É–≤–∞—Ç–∏ –≤–ø–µ–≤–Ω–µ–Ω—ñ—Å—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤—ñ —Å—Ö–æ–∂–∏—Ö –¥–æ—Å–≤—ñ–¥—ñ–≤
        confidence = self._calculate_pattern_confidence(experience, similar_experiences)
        
        # –í–∏–∑–Ω–∞—á–∏—Ç–∏ –≤–∞–≥—É –≤–∞–∂–ª–∏–≤–æ—Å—Ç—ñ
        importance = self._calculate_importance(experience)
        
        return {
            'id': pattern_id,
            'experience': experience,
            'vector': (await self._vectorize_experience(experience)).tolist(),
            'similar_count': len(similar_experiences),
            'confidence': confidence,
            'importance': importance,
            'timestamp': datetime.now().isoformat(),
            'usage_count': 0,
            'success_rate': experience.get('success_rate', 0.5)
        }
        
    def _calculate_pattern_confidence(self, experience: Dict, similar_experiences: List[Dict]) -> float:
        """–†–æ–∑—Ä–∞—Ö—É–≤–∞—Ç–∏ –≤–ø–µ–≤–Ω–µ–Ω—ñ—Å—Ç—å –ø–∞—Ç–µ—Ä–Ω—É"""
        base_confidence = experience.get('success_rate', 0.5)
        
        # –ë–æ–Ω—É—Å –∑–∞ —Å—Ö–æ–∂—ñ —É—Å–ø—ñ—à–Ω—ñ –¥–æ—Å–≤—ñ–¥–∏
        if similar_experiences:
            similar_success_rates = [
                exp['pattern'].get('success_rate', 0.5) 
                for exp in similar_experiences
            ]
            avg_similar_success = sum(similar_success_rates) / len(similar_success_rates)
            base_confidence = (base_confidence + avg_similar_success) / 2
            
        # –ë–æ–Ω—É—Å –∑–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Å—Ö–æ–∂–∏—Ö –¥–æ—Å–≤—ñ–¥—ñ–≤
        similarity_bonus = min(len(similar_experiences) * 0.1, 0.3)
        
        return min(base_confidence + similarity_bonus, 1.0)
        
    def _calculate_importance(self, experience: Dict) -> float:
        """–†–æ–∑—Ä–∞—Ö—É–≤–∞—Ç–∏ –≤–∞–∂–ª–∏–≤—ñ—Å—Ç—å –¥–æ—Å–≤—ñ–¥—É"""
        importance_factors = [
            experience.get('impact', 0.5),
            experience.get('uniqueness', 0.5),
            experience.get('user_feedback', 0.5),
            1.0 if experience.get('critical', False) else 0.3
        ]
        
        return sum(importance_factors) / len(importance_factors)
        
    async def _update_knowledge_base(self, learning_pattern: Dict):
        """–û–Ω–æ–≤–∏—Ç–∏ –±–∞–∑—É –∑–Ω–∞–Ω—å"""
        self.learning_patterns.append(learning_pattern)
        
        # –û–±–º–µ–∂–∏—Ç–∏ —Ä–æ–∑–º—ñ—Ä –±–∞–∑–∏ –∑–Ω–∞–Ω—å
        max_patterns = 1000
        if len(self.learning_patterns) > max_patterns:
            # –í–∏–¥–∞–ª–∏—Ç–∏ –Ω–∞–π–º–µ–Ω—à –≤–∞–∂–ª–∏–≤—ñ –ø–∞—Ç–µ—Ä–Ω–∏
            self.learning_patterns.sort(key=lambda x: x['importance'], reverse=True)
            self.learning_patterns = self.learning_patterns[:max_patterns]
            
        # –û–Ω–æ–≤–∏—Ç–∏ –º–µ—Ç—Ä–∏–∫–∏
        self.performance_metrics['total_learning_sessions'] += 1
        
    async def _adapt_rules(self, learning_pattern: Dict) -> Dict:
        """–ê–¥–∞–ø—Ç—É–≤–∞—Ç–∏ –ø—Ä–∞–≤–∏–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤—ñ –Ω–æ–≤–æ–≥–æ –ø–∞—Ç–µ—Ä–Ω—É"""
        adaptation_applied = False
        
        # –ê–¥–∞–ø—Ç–∞—Ü—ñ—è –ø–æ—Ä–æ–≥—É —Å—Ö–æ–∂–æ—Å—Ç—ñ
        if learning_pattern['confidence'] > 0.8:
            current_threshold = self.adaptation_rules.get('adaptation_threshold', 0.7)
            new_threshold = (current_threshold + learning_pattern['confidence']) / 2
            self.adaptation_rules['adaptation_threshold'] = new_threshold
            adaptation_applied = True
            
        # –ê–¥–∞–ø—Ç–∞—Ü—ñ—è —à–≤–∏–¥–∫–æ—Å—Ç—ñ –Ω–∞–≤—á–∞–Ω–Ω—è
        success_rate = learning_pattern['success_rate']
        if success_rate > 0.8:
            current_lr = self.adaptation_rules.get('learning_rate', 0.1)
            self.adaptation_rules['learning_rate'] = min(current_lr * 1.1, 0.5)
            adaptation_applied = True
        elif success_rate < 0.3:
            current_lr = self.adaptation_rules.get('learning_rate', 0.1)
            self.adaptation_rules['learning_rate'] = max(current_lr * 0.9, 0.01)
            adaptation_applied = True
            
        if adaptation_applied:
            self.performance_metrics['successful_adaptations'] += 1
            
        return {'adapted': adaptation_applied}
        
    def _calculate_knowledge_growth(self) -> float:
        """–†–æ–∑—Ä–∞—Ö—É–≤–∞—Ç–∏ —Ä—ñ—Å—Ç –∑–Ω–∞–Ω—å"""
        if not self.learning_patterns:
            return 0.0
            
        # –°–µ—Ä–µ–¥–Ω—è –≤–ø–µ–≤–Ω–µ–Ω—ñ—Å—Ç—å –≤—Å—ñ—Ö –ø–∞—Ç–µ—Ä–Ω—ñ–≤
        avg_confidence = sum(p['confidence'] for p in self.learning_patterns) / len(self.learning_patterns)
        
        # –†—ñ—Å—Ç –≤—ñ–¥–Ω–æ—Å–Ω–æ –ø–æ—á–∞—Ç–∫–æ–≤–æ–≥–æ —Å—Ç–∞–Ω—É
        baseline_confidence = 0.5
        growth = (avg_confidence - baseline_confidence) / baseline_confidence
        
        return max(growth, 0.0)
        
    async def predict_outcome(self, scenario: Dict) -> Dict:
        """–ü–µ—Ä–µ–¥–±–∞—á–∏—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å—Ü–µ–Ω–∞—Ä—ñ—é"""
        
        scenario_vector = await self._vectorize_experience(scenario)
        similar_patterns = await self._find_similar_experiences(scenario_vector)
        
        if not similar_patterns:
            return {
                'predicted_success_rate': 0.5,
                'confidence': 0.1,
                'recommendations': ['–ù–æ–≤–∏–π —Å—Ü–µ–Ω–∞—Ä—ñ–π, –∑–±–∏—Ä–∞–π—Ç–µ –¥–æ—Å–≤—ñ–¥ –æ–±–µ—Ä–µ–∂–Ω–æ']
            }
            
        # –ó–≤–∞–∂–µ–Ω–µ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è
        weighted_success = 0.0
        total_weight = 0.0
        
        for similar in similar_patterns:
            weight = similar['similarity']
            success_rate = similar['pattern']['success_rate']
            weighted_success += weight * success_rate
            total_weight += weight
            
        predicted_success = weighted_success / total_weight if total_weight > 0 else 0.5
        prediction_confidence = min(total_weight / len(similar_patterns), 1.0)
        
        # –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π
        recommendations = self._generate_recommendations(similar_patterns, scenario)
        
        return {
            'predicted_success_rate': predicted_success,
            'confidence': prediction_confidence,
            'similar_cases': len(similar_patterns),
            'recommendations': recommendations
        }
        
    def _generate_recommendations(self, similar_patterns: List[Dict], scenario: Dict) -> List[str]:
        """–ó–≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó"""
        recommendations = []
        
        # –ê–Ω–∞–ª—ñ–∑ —É—Å–ø—ñ—à–Ω–∏—Ö –ø–∞—Ç–µ—Ä–Ω—ñ–≤
        successful_patterns = [p for p in similar_patterns if p['pattern']['success_rate'] > 0.7]
        
        if successful_patterns:
            recommendations.append("–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ —Å—Ç—Ä–∞—Ç–µ–≥—ñ—ó –∑ —É—Å–ø—ñ—à–Ω–∏—Ö —Å—Ö–æ–∂–∏—Ö –≤–∏–ø–∞–¥–∫—ñ–≤")
            
        # –ê–Ω–∞–ª—ñ–∑ –∫–∞—Ç–µ–≥–æ—Ä—ñ–π
        categories = [p['pattern']['experience'].get('category') for p in similar_patterns]
        most_common_category = max(set(categories), key=categories.count) if categories else None
        
        if most_common_category:
            recommendations.append(f"–†–æ–∑–≥–ª—è–Ω—å—Ç–µ –ø—ñ–¥—Ö–æ–¥–∏ –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó '{most_common_category}'")
            
        # –ó–∞–≥–∞–ª—å–Ω—ñ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó
        if not recommendations:
            recommendations = [
                "–ü–æ—á–Ω—ñ—Ç—å –∑ –ø—Ä–æ—Å—Ç–∏—Ö –∫—Ä–æ–∫—ñ–≤",
                "–ó–±–∏—Ä–∞–π—Ç–µ –∑–≤–æ—Ä–æ—Ç–Ω–∏–π –∑–≤'—è–∑–æ–∫ —Ä–∞–Ω–æ",
                "–ë—É–¥—å—Ç–µ –≥–æ—Ç–æ–≤—ñ –¥–æ –∞–¥–∞–ø—Ç–∞—Ü—ñ—ó"
            ]
            
        return recommendations
        
    async def _save_knowledge_base(self, data: Dict = None):
        """–ó–±–µ—Ä–µ–≥—Ç–∏ –±–∞–∑—É –∑–Ω–∞–Ω—å"""
        if data is None:
            data = {
                'patterns': self.learning_patterns,
                'rules': self.adaptation_rules,
                'metrics': self.performance_metrics
            }
            
        try:
            with open(self.knowledge_base_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
        except Exception:
            pass  # –Ü–≥–Ω–æ—Ä—É—î–º–æ –ø–æ–º–∏–ª–∫–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è
            
    def get_learning_stats(self) -> Dict:
        """–û—Ç—Ä–∏–º–∞—Ç–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –Ω–∞–≤—á–∞–Ω–Ω—è"""
        return {
            'total_patterns': len(self.learning_patterns),
            'knowledge_growth': self._calculate_knowledge_growth(),
            'adaptation_rules': self.adaptation_rules.copy(),
            'performance_metrics': self.performance_metrics.copy(),
            'average_confidence': sum(p['confidence'] for p in self.learning_patterns) / len(self.learning_patterns) if self.learning_patterns else 0.0
        }
        
    async def forget_outdated_knowledge(self, age_threshold_days: int = 30):
        """–ó–∞–±—É—Ç–∏ –∑–∞—Å—Ç–∞—Ä—ñ–ª—ñ –∑–Ω–∞–Ω–Ω—è"""
        current_time = datetime.now()
        forget_threshold = self.adaptation_rules.get('forget_threshold', 0.3)
        
        patterns_to_keep = []
        
        for pattern in self.learning_patterns:
            pattern_time = datetime.fromisoformat(pattern['timestamp'])
            age_days = (current_time - pattern_time).days
            
            # –ó–±–µ—Ä–µ–≥—Ç–∏ —è–∫—â–æ: –≤–∞–∂–ª–∏–≤–µ –ê–ë–û –Ω–µ–¥–∞–≤–Ω—î –ê–ë–û —É—Å–ø—ñ—à–Ω–µ
            keep = (
                pattern['importance'] > forget_threshold or
                age_days < age_threshold_days or
                pattern['success_rate'] > 0.8
            )
            
            if keep:
                patterns_to_keep.append(pattern)
                
        forgotten_count = len(self.learning_patterns) - len(patterns_to_keep)
        self.learning_patterns = patterns_to_keep
        
        # –û–Ω–æ–≤–∏—Ç–∏ –º–µ—Ç—Ä–∏–∫–∏
        if forgotten_count > 0:
            retention_rate = len(patterns_to_keep) / (len(patterns_to_keep) + forgotten_count)
            self.performance_metrics['knowledge_retention_rate'] = retention_rate
            
        return {'forgotten_patterns': forgotten_count}


# –ü—Ä–∏–∫–ª–∞–¥ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è
async def main():
    learning_module = LearningModule("test_knowledge.json")
    
    # –°–∏–º—É–ª—è—Ü—ñ—è –¥–æ—Å–≤—ñ–¥—É –Ω–∞–≤—á–∞–Ω–Ω—è
    experience = {
        'description': 'Successfully implemented AI task prioritization',
        'category': 'technical',
        'success_rate': 0.9,
        'complexity': 0.7,
        'time_taken': 2.5,
        'user_satisfaction': 0.8,
        'impact': 0.9,
        'uniqueness': 0.6,
        'critical': True
    }
    
    # –ù–∞–≤—á–∞–Ω–Ω—è
    result = await learning_module.learn_from_experience(experience)
    print("Learning Result:", result)
    
    # –ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è
    new_scenario = {
        'description': 'Implementing error detection system',
        'category': 'technical',
        'complexity': 0.8
    }
    
    prediction = await learning_module.predict_outcome(new_scenario)
    print("Prediction:", prediction)
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    stats = learning_module.get_learning_stats()
    print("Learning Stats:", stats)

if __name__ == "__main__":
    asyncio.run(main())
'''

            with open(learning_module_path, "w", encoding="utf-8") as f:
                f.write(learning_code)

            self.log_step("LearningModule —É—Å–ø—ñ—à–Ω–æ —Å—Ç–≤–æ—Ä–µ–Ω–æ!", "SUCCESS")
            return True

        except Exception as e:
            self.log_step(f"–ü–æ–º–∏–ª–∫–∞ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è LearningModule: {e}", "ERROR")
            return False

    # –î–æ–¥–∞—Ç–∫–æ–≤—ñ –º–µ—Ç–æ–¥–∏ –¥–ª—è —ñ–Ω—à–∏—Ö —Ç–∏–ø—ñ–≤ –∑–∞–≤–¥–∞–Ω—å
    async def _create_worker_agent_real(self) -> bool:
        """–°—Ç–≤–æ—Ä–∏—Ç–∏ —Ä–µ–∞–ª—å–Ω–∏–π WorkerAgent"""
        self.log_step("–°—Ç–≤–æ—Ä–µ–Ω–Ω—è WorkerAgent –∑ –∞–≤—Ç–æ–Ω–æ–º–Ω–∏–º–∏ –Ω–∞–≤–∏—á–∫–∞–º–∏...", "PROCESS")
        await asyncio.sleep(1)
        self.log_step("WorkerAgent —Å—Ç–≤–æ—Ä–µ–Ω–æ (–∑–∞–≥–ª—É—à–∫–∞)", "SUCCESS")
        return True

    async def _create_macos_integration_real(self) -> bool:
        """–°—Ç–≤–æ—Ä–∏—Ç–∏ —Ä–µ–∞–ª—å–Ω—É macOS —ñ–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—é"""
        self.log_step(
            "–°—Ç–≤–æ—Ä–µ–Ω–Ω—è macOS Integration –∑ —Å–∏—Å—Ç–µ–º–Ω–æ—é —ñ–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—î—é...", "PROCESS"
        )
        await asyncio.sleep(1)
        self.log_step("macOS Integration —Å—Ç–≤–æ—Ä–µ–Ω–æ (–∑–∞–≥–ª—É—à–∫–∞)", "SUCCESS")
        return True

    async def _create_package_installer(self) -> bool:
        """–°—Ç–≤–æ—Ä–∏—Ç–∏ —ñ–Ω—Å—Ç–∞–ª—è—Ç–æ—Ä –ø–∞–∫–µ—Ç—ñ–≤"""
        self.log_step("–°—Ç–≤–æ—Ä–µ–Ω–Ω—è —ñ–Ω—Ç–µ–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–≥–æ —ñ–Ω—Å—Ç–∞–ª—è—Ç–æ—Ä–∞ –ø–∞–∫–µ—Ç—ñ–≤...", "PROCESS")
        await asyncio.sleep(1)
        self.log_step("–Ü–Ω—Å—Ç–∞–ª—è—Ç–æ—Ä –ø–∞–∫–µ—Ç—ñ–≤ —Å—Ç–≤–æ—Ä–µ–Ω–æ (–∑–∞–≥–ª—É—à–∫–∞)", "SUCCESS")
        return True

    async def _create_validation_system(self) -> bool:
        """–°—Ç–≤–æ—Ä–∏—Ç–∏ —Å–∏—Å—Ç–µ–º—É –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó"""
        self.log_step("–°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Å–∏—Å—Ç–µ–º–∏ –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞...", "PROCESS")
        await asyncio.sleep(1)
        self.log_step("–°–∏—Å—Ç–µ–º–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó —Å—Ç–≤–æ—Ä–µ–Ω–∞ (–∑–∞–≥–ª—É—à–∫–∞)", "SUCCESS")
        return True

    async def _create_configuration_system(self) -> bool:
        """–°—Ç–≤–æ—Ä–∏—Ç–∏ —Å–∏—Å—Ç–µ–º—É –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó"""
        self.log_step("–°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Å–∏—Å—Ç–µ–º–∏ –¥–∏–Ω–∞–º—ñ—á–Ω–æ–≥–æ –∫–æ–Ω—Ñ—ñ–≥—É—Ä—É–≤–∞–Ω–Ω—è...", "PROCESS")
        await asyncio.sleep(1)
        self.log_step("–°–∏—Å—Ç–µ–º–∞ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó —Å—Ç–≤–æ—Ä–µ–Ω–∞ (–∑–∞–≥–ª—É—à–∫–∞)", "SUCCESS")
        return True

    async def _generate_real_documentation(self) -> bool:
        """–ó–≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ —Ä–µ–∞–ª—å–Ω—É –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—é"""
        self.log_step("–ì–µ–Ω–µ—Ä–∞—Ü—ñ—è —Ä–µ–∞–ª—å–Ω–æ—ó –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—ó –ø—Ä–æ–µ–∫—Ç—É...", "PROCESS")
        await asyncio.sleep(1)
        self.log_step("–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—è –∑–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–∞ (–∑–∞–≥–ª—É—à–∫–∞)", "SUCCESS")
        return True

    async def _create_real_tests(self) -> bool:
        """–°—Ç–≤–æ—Ä–∏—Ç–∏ —Ä–µ–∞–ª—å–Ω—ñ —Ç–µ—Å—Ç–∏"""
        self.log_step("–°—Ç–≤–æ—Ä–µ–Ω–Ω—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–∏—Ö —Ç–µ—Å—Ç—ñ–≤...", "PROCESS")
        await asyncio.sleep(1)
        self.log_step("–¢–µ—Å—Ç–∏ —Å—Ç–≤–æ—Ä–µ–Ω—ñ (–∑–∞–≥–ª—É—à–∫–∞)", "SUCCESS")
        return True

    async def _execute_generic_task(self, task: Dict) -> bool:
        """–í–∏–∫–æ–Ω–∞—Ç–∏ –∑–∞–≥–∞–ª—å–Ω–µ –∑–∞–≤–¥–∞–Ω–Ω—è"""
        self.log_step(f"–í–∏–∫–æ–Ω–∞–Ω–Ω—è –∑–∞–≥–∞–ª—å–Ω–æ–≥–æ –∑–∞–≤–¥–∞–Ω–Ω—è: {task['title']}", "PROCESS")
        await asyncio.sleep(0.5)
        self.log_step("–ó–∞–≥–∞–ª—å–Ω–µ –∑–∞–≤–¥–∞–Ω–Ω—è –≤–∏–∫–æ–Ω–∞–Ω–æ", "SUCCESS")
        return True

    async def _mark_task_completed(self, task: Dict):
        """–ü–æ–∑–Ω–∞—á–∏—Ç–∏ –∑–∞–≤–¥–∞–Ω–Ω—è —è–∫ –∑–∞–≤–µ—Ä—à–µ–Ω–µ –≤ DEV_PLAN.md"""
        try:
            with open(self.devplan_path, "r", encoding="utf-8") as f:
                content = f.read()

            # –ó–∞–º—ñ–Ω–∏—Ç–∏ [ ] –Ω–∞ [x] –¥–ª—è —Ü—å–æ–≥–æ –∑–∞–≤–¥–∞–Ω–Ω—è
            original_line = task["original_line"]
            completed_line = original_line.replace("- [ ]", "- [x]")

            new_content = content.replace(original_line, completed_line)

            if new_content != content:
                with open(self.devplan_path, "w", encoding="utf-8") as f:
                    f.write(new_content)

                self.log_step(
                    f"–ó–∞–≤–¥–∞–Ω–Ω—è –ø–æ–∑–Ω–∞—á–µ–Ω–æ —è–∫ –∑–∞–≤–µ—Ä—à–µ–Ω–µ: {task['title']}", "SUCCESS"
                )

        except Exception as e:
            self.log_step(f"–ü–æ–º–∏–ª–∫–∞ –ø–æ–∑–Ω–∞—á–µ–Ω–Ω—è –∑–∞–≤–¥–∞–Ω–Ω—è: {e}", "ERROR")

    async def _generate_execution_report(self):
        """–ó–≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ –∑–≤—ñ—Ç –ø—Ä–æ –≤–∏–∫–æ–Ω–∞–Ω–Ω—è"""
        self.log_step("", "INFO")
        print("=" * 60)
        self.log_step("üìä –ó–í–Ü–¢ –ü–†–û –í–ò–ö–û–ù–ê–ù–ù–Ø –†–ï–ê–õ–¨–ù–ò–• –ó–ê–í–î–ê–ù–¨", "SUCCESS")
        print("=" * 60)

        if self.executed_tasks:
            self.log_step(f"‚úÖ –í–∏–∫–æ–Ω–∞–Ω–æ –∑–∞–≤–¥–∞–Ω—å: {len(self.executed_tasks)}", "SUCCESS")

            for i, task in enumerate(self.executed_tasks, 1):
                self.log_step(f"   {i}. {task['title']} ({task['phase']})", "INFO")

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ñ–∞–∑–∞—Ö
            phases = {}
            for task in self.executed_tasks:
                phase = task["phase"]
                phases[phase] = phases.get(phase, 0) + 1

            self.log_step("üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ñ–∞–∑–∞—Ö:", "INFO")
            for phase, count in phases.items():
                self.log_step(f"   {phase}: {count} –∑–∞–≤–¥–∞–Ω—å", "INFO")

        else:
            self.log_step("‚ö†Ô∏è –ñ–æ–¥–Ω–µ –∑–∞–≤–¥–∞–Ω–Ω—è –Ω–µ –±—É–ª–æ –≤–∏–∫–æ–Ω–∞–Ω–æ", "WARNING")

        print("=" * 60)
        self.log_step("üéâ –†–ï–ê–õ–¨–ù–ò–ô –í–ò–ö–û–ù–ê–í–ï–¶–¨ –ó–ê–í–ï–†–®–ò–í –†–û–ë–û–¢–£!", "SUCCESS")


# –ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è
async def main():
    executor = RealDevPlanExecutor()
    await executor.execute_real_devplan_tasks()


if __name__ == "__main__":
    asyncio.run(main())
